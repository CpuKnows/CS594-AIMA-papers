{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "64ca7da9-7a17-4af9-9a6b-18afbbf02827"
    }
   },
   "source": [
    "# Resources\n",
    "\n",
    "http://allennlp.org/tutorials  \n",
    "https://github.com/allenai/allennlp  \n",
    "https://s3-us-west-2.amazonaws.com/allennlp/models/srl-model-2017.09.05.tar.gz  \n",
    "https://spacy.io/usage/processing-pipelines  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "13534d5f-1a60-4a2c-94e2-da17f5174d97"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drqa/miniconda3/envs/nlsparkle/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "from nltk.corpus import verbnet, wordnet\n",
    "from nltk.classify.maxent import MaxentClassifier, accuracy\n",
    "\n",
    "from allennlp.service.predictors import SemanticRoleLabelerPredictor\n",
    "from allennlp.models.archival import load_archive\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Doc, Span, Token\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66d8460c-2c55-482b-b60c-4ee7837bbe46"
    }
   },
   "source": [
    "# Semantic role labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "0aadf341-00d2-424d-bef4-ff6281efd6d6"
    }
   },
   "outputs": [],
   "source": [
    "class SRLTagger(object):\n",
    "    name = 'SRLTagger'\n",
    "    \n",
    "    def __init__(self, vocab, srl_predictor):\n",
    "        self.vocab = vocab\n",
    "        self.srl_predictor = srl_predictor\n",
    "        \n",
    "        Token.set_extension('srl_tag', default='O')\n",
    "        #Span.set_extension('srl_tag', default='O')\n",
    "        \n",
    "    def __call__(self, doc):\n",
    "        predictions = self.srl_predictor.predict_json({'sentence': doc.text})\n",
    "        \n",
    "        if len(predictions['verbs']):\n",
    "            for i, token in enumerate(doc):\n",
    "                if token.text == predictions['tokens'][i]:\n",
    "                    token._.set('srl_tag', predictions['verbs'][0]['tags'][i])\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "50a608ac-b12d-4e9a-a810-e87fd16a7f14"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Did not use initialization regex that was passed: stacked_encoder\\\\\\\\._module.layer_.*bias\n",
      "Did not use initialization regex that was passed: stacked_encoder\\\\\\\\._module.layer_0\\\\\\\\.input_linearity\\\\\\\\.weight\n",
      "Did not use initialization regex that was passed: stacked_encoder\\\\\\\\._module\\\\\\\\.layer_0\\\\\\\\.state_linearity\\\\\\\\.weight\n"
     ]
    }
   ],
   "source": [
    "archive = load_archive('../models/srl-model-2017.09.05.tar.gz')\n",
    "predictor = SemanticRoleLabelerPredictor.from_archive(archive, \"semantic-role-labeling\")\n",
    "\n",
    "srl_tagger = SRLTagger(nlp, predictor)\n",
    "nlp.add_pipe(srl_tagger, last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "325930da-314f-4344-903a-336b37302bec"
    }
   },
   "outputs": [],
   "source": [
    "#doc = nlp('What cartel trades guns illegally?')\n",
    "doc = nlp('Who wrote The Little Prince?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "319cf316-9b64-4e3a-840f-cb1ba5c2afda"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who\tB-ARG0\n",
      "wrote\tB-V\n",
      "The\tB-ARG1\n",
      "Little\tI-ARG1\n",
      "Prince\tI-ARG1\n",
      "?\tO\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, token._.srl_tag, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "82752770-7ace-4395-812f-ede6d6dfa070"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Little Prince\tWORK_OF_ART\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "560cace7-9fa2-427b-b9d5-5dd22dd56ed2"
    }
   },
   "source": [
    "# WordNet and VerbNet Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbpresent": {
     "id": "dc7cf20b-90e7-4f0f-b75d-db3f97684959"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: ['She composed a poem', 'He wrote four novels']\n",
      "POS: v\n",
      "Hypernyms: [Synset('create_verbally.v.01')]\n",
      "Hyponyms:\n",
      "[Synset('annotate.v.01'),\n",
      " Synset('author.v.01'),\n",
      " Synset('dash_off.v.01'),\n",
      " Synset('draft.v.01'),\n",
      " Synset('dramatize.v.01'),\n",
      " Synset('draw.v.18'),\n",
      " Synset('lyric.v.01'),\n",
      " Synset('paragraph.v.02'),\n",
      " Synset('paragraph.v.03'),\n",
      " Synset('profile.v.01'),\n",
      " Synset('reference.v.01'),\n",
      " Synset('rewrite.v.02'),\n",
      " Synset('script.v.01'),\n",
      " Synset('verse.v.01'),\n",
      " Synset('write_copy.v.01'),\n",
      " Synset('write_off.v.02'),\n",
      " Synset('write_on.v.01'),\n",
      " Synset('write_out.v.01')]\n",
      "WordNet name: write.v.01\n",
      "Lemmas:\n",
      "[Lemma('write.v.01.write'),\n",
      " Lemma('write.v.01.compose'),\n",
      " Lemma('write.v.01.pen'),\n",
      " Lemma('write.v.01.indite')]\n"
     ]
    }
   ],
   "source": [
    "wn = wordnet.synsets('wrote')[0]\n",
    "print('Examples:', wn.examples())\n",
    "print('POS:', wn.pos())\n",
    "print('Hypernyms:', wn.hypernyms())\n",
    "print('Hyponyms:')\n",
    "pprint.pprint(wn.hyponyms())\n",
    "print('WordNet name:', wn.name())\n",
    "print('Lemmas:')\n",
    "pprint.pprint(wn.lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbpresent": {
     "id": "6c6fff5b-da99-4fd0-8b24-68fa186a1860"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lecture-37.11-1\\n  Subclasses: lecture-37.11-1-1\\n  Members: lecture moralize preach remark speak talk theorize write\\n  Thematic roles:\\n\\n  Frames:\\n    Basic Intransitive\\n      Example: She lectured.\\n      Syntax: NP[Agent] VERB\\n      Semantics:\\n        * transfer_info(during(E), Agent, ?Recipient, ?Topic)\\n        * cause(Agent, E)\\n    PP (about-PP)\\n      Example: She lectured about her travels.\\n      Syntax: NP[Agent] VERB PREP[about] NP[Topic -sentential]\\n      Semantics:\\n        * transfer_info(during(E), Agent, ?Recipient, Topic)\\n        * cause(Agent, E)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnclass = verbnet.vnclass(verbnet.classids('write')[0])\n",
    "verbnet.pprint(vnclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "132da013-a9c7-4522-80a1-784df0e78f2e"
    }
   },
   "source": [
    "# Answer Type Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../models/maxent_classifier.pkl', 'rb') as f:\n",
    "    maxent_classifier = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazy feature creation - spacy\n",
    "def create_features(doc):\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "    ner_tags = [ent.label_ for ent in doc.ents]\n",
    "    \n",
    "    features = {}\n",
    "    features\n",
    "    features['person'] = 'PERSON' in ner_tags\n",
    "    features['work_of_art'] = 'WORK_OF_ART' in ner_tags\n",
    "    features['proper_noun'] = ('NNP' or 'NNPS') in pos_tags\n",
    "    features['length'] = len(doc)\n",
    "    features['lemma_1'] = doc[0].lemma_\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_type = maxent_classifier.classify_many([create_features(doc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbpresent": {
     "id": "ebedd1ec-1978-46f0-908c-65141d2c9c65"
    }
   },
   "outputs": [],
   "source": [
    "answer_type = 'HUM:ind'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b0b2f6ec-593e-472c-b7eb-e4d026ebb754"
    }
   },
   "source": [
    "# SPARQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "nbpresent": {
     "id": "bce661c3-3805-400f-8820-2b39040d9194"
    }
   },
   "outputs": [],
   "source": [
    "def create_sparql_query(doc, answer_type):\n",
    "    \n",
    "    for token in doc:\n",
    "        if token._.srl_tag == 'B-V':\n",
    "            predicate = token.lemma_\n",
    "            break\n",
    "    \n",
    "    query = 'SELECT DISTINCT ?x2 WHERE {\\n'\n",
    "\n",
    "    if ('who' in [token.lemma_ for token in doc] and \n",
    "        answer_type == 'HUM:ind'):\n",
    "        \n",
    "        query += ('\\t?x0 rdf:type foaf:Person.\\n' +\n",
    "                  '\\t?x0 foaf:name ?x2.\\n')\n",
    "\n",
    "        if predicate and predicate == 'write':\n",
    "            query += ('\\t?x1 rdf:type dbpedia-owl:Book.\\n' +\n",
    "                      '\\t?x1 dbpedia-owl:author ?x0.\\n')\n",
    "            \n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'WORK_OF_ART':\n",
    "                query += '\\t?x1 rdfs:label \"' + ent.text + '\"@en.\\n'\n",
    "                break\n",
    "        \n",
    "    query += '}'\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbpresent": {
     "id": "0d54c69c-21f6-4cd0-b10e-30f3d55820ce"
    }
   },
   "outputs": [],
   "source": [
    "def print_sparql_answer(answer):\n",
    "    if answer['results']['bindings']:\n",
    "        for ans in answer['results']['bindings']:\n",
    "            if ans['x2']['xml:lang'] == 'en':\n",
    "                print(ans['x2']['value'])\n",
    "    else:\n",
    "        print('No results returned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "nbpresent": {
     "id": "b3ed2521-0c13-4766-85b4-621d715e610b"
    }
   },
   "outputs": [],
   "source": [
    "sparql = SPARQLWrapper('http://dbpedia.org/sparql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "nbpresent": {
     "id": "24e882ef-d7b4-4dc6-9f59-5f209bd46b3b"
    }
   },
   "outputs": [],
   "source": [
    "# PREFIX dbres: <http://dbpedia.org/resource/>\n",
    "\n",
    "prefix = \"\"\"\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "PREFIX quepy: <http://www.machinalis.com/quepy#>\n",
    "PREFIX dbpedia: <http://dbpedia.org/ontology/>\n",
    "PREFIX dbpprop: <http://dbpedia.org/property/>\n",
    "PREFIX dbpedia-owl: <http://dbpedia.org/ontology/>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "nbpresent": {
     "id": "297965d2-1fc2-44e6-97e7-298c01bac286"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
      "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
      "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
      "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
      "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
      "PREFIX quepy: <http://www.machinalis.com/quepy#>\n",
      "PREFIX dbpedia: <http://dbpedia.org/ontology/>\n",
      "PREFIX dbpprop: <http://dbpedia.org/property/>\n",
      "PREFIX dbpedia-owl: <http://dbpedia.org/ontology/>\n",
      "\n",
      "SELECT DISTINCT ?x2 WHERE {\n",
      "\t?x0 rdf:type foaf:Person.\n",
      "\t?x0 foaf:name ?x2.\n",
      "\t?x1 rdf:type dbpedia-owl:Book.\n",
      "\t?x1 dbpedia-owl:author ?x0.\n",
      "\t?x1 rdfs:label \"The Little Prince\"@en.\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = create_sparql_query(doc, answer_type)\n",
    "query = prefix + query\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "nbpresent": {
     "id": "0cd93677-d65d-4371-99e4-1acee5bdbad9"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antoine de Saint-Exupéry\n"
     ]
    }
   ],
   "source": [
    "sparql.setQuery(query)\n",
    "sparql.setReturnFormat(JSON)\n",
    "answer = sparql.query().convert()\n",
    "\n",
    "print_sparql_answer(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlsparkle]",
   "language": "python",
   "name": "conda-env-nlsparkle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
